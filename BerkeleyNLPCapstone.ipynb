{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berkeley NLP Capstone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Steven Johannemann, Zoe Ouyang, Chloe Zhang\n",
    "#Import all needed packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import string\n",
    "from string import punctuation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset and Word2vec file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the data\n",
    "df_ori = pd.read_csv('yelp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Basic View of Data\n",
    "df_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape of Data\n",
    "df_ori.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new column for Binary Classification where 1-2 stars = negative (0) and 3-5 stars = positive (1)\n",
    "df_ori[\"attitude\"] = np.where(df_ori[\"stars\"] >= 3, 1, 0)\n",
    "#Create a new data frame that only contains the following columns\n",
    "df = df_ori[['text','attitude']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    8324\n",
       "0    1676\n",
       "Name: attitude, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examine the distribution of the 'attitude' column\n",
    "df['attitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['attitude'].astype(int).plot.hist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1e2c73960a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Correlation between review length and rating may be insightful\n",
    "df_ori['length of text'] = df_ori['text'].apply(len)\n",
    "graph = sns.FacetGrid(data=df_ori,col='stars')\n",
    "graph.map(plt.hist,'length of text',bins=50,color='purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can work more on this later to create more visuals and figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for data cleaning using regular expressions\n",
    "import re\n",
    "def function_clean(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) #hyperlinks\n",
    "    text = re.sub(\"@[^\\s]*\", \"\", text)\n",
    "    text = re.sub(\"#[^\\s]*\", \"\", text)\n",
    "    text = re.sub('[0-9]*[+-:]*[0-9]+', '', text) #Dates\n",
    "    text = re.sub(\"'s\", \"\", text) # \" 's \"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-2c6fb3533ba0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].apply(lambda text: function_clean(text))\n"
     ]
    }
   ],
   "source": [
    "#Apply the regex function to text column\n",
    "df['text'] = df['text'].apply(lambda text: function_clean(text))\n",
    "X = df['text']\n",
    "y = df[\"attitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "    listofwords = sentence.strip().split()          \n",
    "    listof_words = []    \n",
    "    for word in listofwords:\n",
    "        if not word in stop_words:\n",
    "            stem_word = porter.stem(word)\n",
    "            for punctuation_mark in string.punctuation:\n",
    "                stem_word = stem_word.replace(punctuation_mark, '').lower()\n",
    "            if len(word)>2:\n",
    "                listof_words.append(stem_word)\n",
    "    return(listof_words)\n",
    "\n",
    "#preprocess the text.\n",
    "def preprocess_corpus(texts):\n",
    "    mystopwords = set(stopwords.words(\"english\"))\n",
    "    def remove_stops_digits(tokens):\n",
    "        #Nested function that lowercases, removes stopwords and digits from a list of tokens\n",
    "        return [token.lower() for token in tokens if token not in mystopwords and not token.isdigit()\n",
    "               and token not in punctuation and len(token) > 2]\n",
    "    #This return statement below uses the above function to process twitter tokenizer output further. \n",
    "    return [remove_stops_digits(word_tokenize(text)) for text in texts]\n",
    "\n",
    "# Creating a feature vector by averaging all embeddings for all sentences\n",
    "def embedding_feats(list_of_lists):\n",
    "    DIMENSION = 300\n",
    "    zero_vector = np.zeros(DIMENSION)\n",
    "    feats = []\n",
    "    for tokens in list_of_lists:\n",
    "        feat_for_this =  np.zeros(DIMENSION)\n",
    "        count_for_this = 0\n",
    "        for token in tokens:\n",
    "            if token in w2v_model:\n",
    "                feat_for_this += w2v_model[token]\n",
    "                count_for_this +=1\n",
    "        if count_for_this == 0:\n",
    "            count_for_this = 1\n",
    "        feats.append(feat_for_this/count_for_this)\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training/testing split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.5 s\n",
      "done loading Word2Vec\n"
     ]
    }
   ],
   "source": [
    "#Load the pre-trained word2vec model and the dataset\n",
    "data_path= r\"C:\\Users\\Steven Johannemann\\Desktop\\Capstone\\Capstone Notebooks\"\n",
    "path_to_model = os.path.join(data_path,'GoogleNews-vectors-negative300.bin')\n",
    "training_data_path = os.path.join(data_path, \"sentiment_sentences.txt\")\n",
    "\n",
    "#Load W2V model. This will take some time. \n",
    "%time w2v_model = KeyedVectors.load_word2vec_format(path_to_model, binary=True)\n",
    "print('done loading Word2Vec')\n",
    "\n",
    "#Read text data, cats.\n",
    "#the file path consists of tab separated sentences and cats.\n",
    "train_texts = X_train.tolist()\n",
    "train_cats = y_train.tolist()\n",
    "test_texts = X_test.tolist()\n",
    "test_cats = y_test.tolist()\n",
    "#fh = open(training_data_path)\n",
    "#for line in fh:\n",
    "#    text, sentiment = line.split(\"\\t\")\n",
    "#    texts.append(text)\n",
    "#    cats.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000\n"
     ]
    }
   ],
   "source": [
    "# Inspect the model\n",
    "word2vec_vocab = w2v_model.vocab.keys()\n",
    "word2vec_vocab_lower = [item.lower() for item in word2vec_vocab]\n",
    "print(len(word2vec_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one thing to note is that word embedding models do not require the same amount of cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heuristic NLP model (VADER sentiment analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Steven\n",
      "[nltk_data]     Johannemann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer type of data from DataFrame into dictionary and preprocess the text for later sentiment intensity analysis\n",
    "import re\n",
    "PATTERN = r'[^a-zA]' \n",
    "#df_senti = df_ori[['text']]\n",
    "df_senti = X_test.to_frame()\n",
    "senti=df_senti.to_dict('records') \n",
    "for cell in senti: \n",
    "    cell_1 = cell['text'].replace('\\n','').replace('\\n\\n','').lower()\n",
    "    cell_2 = re.sub(PATTERN,r' ',cell_1)\n",
    "    cell_2_no_punc= cell_2.translate(str.maketrans('','', string.punctuation))\n",
    "    ss = sid.polarity_scores(cell_2_no_punc)\n",
    "    cell.update(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>prediction</th>\n",
       "      <th>attitude</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First let me start by saying they're beer sele...</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.757</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My boyfriends company has been doing business ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.705</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.8313</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This place used to be amazing.  My favorite me...</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.064</td>\n",
       "      <td>-0.9516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I took my daughter there to get her nose pierc...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.410</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This place is perfect! Great food, great servi...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.644</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    neg    neu    pos  \\\n",
       "0  First let me start by saying they're beer sele...  0.055  0.757  0.188   \n",
       "1  My boyfriends company has been doing business ...  0.000  0.705  0.295   \n",
       "2  This place used to be amazing.  My favorite me...  0.101  0.835  0.064   \n",
       "3  I took my daughter there to get her nose pierc...  0.000  0.590  0.410   \n",
       "4  This place is perfect! Great food, great servi...  0.000  0.644  0.356   \n",
       "\n",
       "   compound  prediction  attitude  match  \n",
       "0    0.9784           1         1      1  \n",
       "1    0.8313           1         1      1  \n",
       "2   -0.9516           0         0      1  \n",
       "3    0.9693           1         1      1  \n",
       "4    0.9628           1         1      1  "
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_senti_score=pd.DataFrame.from_dict(senti)\n",
    "df_senti_score[\"prediction\"] = np.where(df_senti_score[\"pos\"] > df_senti_score[\"neg\"], 1, 0)\n",
    "df_vader = pd.concat([df_senti_score.reset_index(drop=True),y_test.to_frame().reset_index(drop=True)], axis=1)\n",
    "df_vader[\"match\"] = np.where(df_vader[\"prediction\"] == df_vader[\"attitude\"], 1, 0)\n",
    "df_vader.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "00     198\n",
       "01     287\n",
       "10      92\n",
       "11    2423\n",
       "dtype: int64"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "cats = ['{0[0]}{0[1]}'.format(tup) for tup in product([0,1], [0,1])]\n",
    "pd.Categorical((df_vader.attitude.astype(str)+df_vader.prediction.astype(str)),categories=cats).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Heuristic Model 0.8736666666666667.\n"
     ]
    }
   ],
   "source": [
    "vader_accuracy = df_vader[\"match\"].sum()/df_vader[\"match\"].count()\n",
    "print(f'Accuracy of the Heuristic Model {vader_accuracy}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction using BoW, Tf-idf and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "#Use CountVectorizer for BoW and TfidfVectorizer for Tf-idf\n",
    "cv = CountVectorizer(tokenizer = my_tokenizer, ngram_range=(1,3), min_df = 0.001).fit(X_train)\n",
    "tfidf = TfidfVectorizer(tokenizer = my_tokenizer, ngram_range=(1,3), min_df = 0.001).fit(X_train)\n",
    "X_traintfidf = tfidf.transform(X_train)\n",
    "X_testtfidf = tfidf.transform(X_test)\n",
    "X_traincv = cv.transform(X_train)\n",
    "X_testcv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_processed = preprocess_corpus(train_texts)\n",
    "train_texts_vectors = embedding_feats(train_texts_processed)\n",
    "\n",
    "test_texts_processed = preprocess_corpus(test_texts)\n",
    "test_texts_vectors = embedding_feats(test_texts_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preview First 100 Feature Names\n",
    "#cv.get_feature_names()[0:100]\n",
    "#tfidf.get_feature_names()[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 10359)\n",
      "(7000, 10359)\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "#Shape of the training sets after feature extraction\n",
    "print(X_traincv.shape)\n",
    "print(X_traintfidf.shape)\n",
    "print(len(train_texts_vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5809\n",
      "1    5809\n",
      "Name: attitude, dtype: int64\n",
      "0    5809\n",
      "1    5809\n",
      "Name: attitude, dtype: int64\n",
      "0    5809\n",
      "1    5809\n",
      "Name: attitude, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=6)\n",
    "X_balcv, y_balcv = sm.fit_resample(X_traincv, y_train)\n",
    "X_baltfidf, y_baltfidf = sm.fit_resample(X_traintfidf, y_train)\n",
    "\n",
    "df_train_vect = DataFrame(train_texts_vectors,columns=[f\"{x}\" for x in range(0,300)])\n",
    "X_bal_w2v_train, y_bal_w2v_train = sm.fit_resample(df_train_vect, y_train)\n",
    "X_bal_w2v_test = DataFrame(test_texts_vectors,columns=[f\"{x}\" for x in range(0,300)])\n",
    "\n",
    "print(y_balcv.value_counts())\n",
    "print(y_baltfidf.value_counts())\n",
    "print(y_bal_w2v_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal_w2v_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023744</td>\n",
       "      <td>0.060219</td>\n",
       "      <td>0.016482</td>\n",
       "      <td>0.090105</td>\n",
       "      <td>-0.007244</td>\n",
       "      <td>-0.025589</td>\n",
       "      <td>0.034035</td>\n",
       "      <td>-0.113440</td>\n",
       "      <td>0.054746</td>\n",
       "      <td>0.114717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056137</td>\n",
       "      <td>0.021115</td>\n",
       "      <td>-0.082917</td>\n",
       "      <td>0.063784</td>\n",
       "      <td>0.043157</td>\n",
       "      <td>-0.026655</td>\n",
       "      <td>-0.040477</td>\n",
       "      <td>-0.025094</td>\n",
       "      <td>0.054904</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.015911</td>\n",
       "      <td>0.043575</td>\n",
       "      <td>-0.013652</td>\n",
       "      <td>0.100484</td>\n",
       "      <td>-0.005798</td>\n",
       "      <td>-0.015063</td>\n",
       "      <td>0.061395</td>\n",
       "      <td>-0.072637</td>\n",
       "      <td>0.067469</td>\n",
       "      <td>0.103962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038242</td>\n",
       "      <td>0.030037</td>\n",
       "      <td>-0.157944</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>-0.003957</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.006192</td>\n",
       "      <td>-0.096130</td>\n",
       "      <td>0.038877</td>\n",
       "      <td>-0.055206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.046297</td>\n",
       "      <td>0.020967</td>\n",
       "      <td>-0.013677</td>\n",
       "      <td>0.139245</td>\n",
       "      <td>-0.012362</td>\n",
       "      <td>0.013418</td>\n",
       "      <td>0.070208</td>\n",
       "      <td>-0.079559</td>\n",
       "      <td>0.020009</td>\n",
       "      <td>0.104837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003211</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>-0.082918</td>\n",
       "      <td>0.050714</td>\n",
       "      <td>0.012108</td>\n",
       "      <td>-0.075983</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>-0.033747</td>\n",
       "      <td>0.014359</td>\n",
       "      <td>-0.000162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008420</td>\n",
       "      <td>0.075425</td>\n",
       "      <td>0.024882</td>\n",
       "      <td>0.172981</td>\n",
       "      <td>-0.074955</td>\n",
       "      <td>-0.002558</td>\n",
       "      <td>0.046766</td>\n",
       "      <td>-0.103122</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>0.140211</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073666</td>\n",
       "      <td>0.068075</td>\n",
       "      <td>-0.044182</td>\n",
       "      <td>0.050248</td>\n",
       "      <td>0.045441</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>-0.008546</td>\n",
       "      <td>-0.096064</td>\n",
       "      <td>0.009728</td>\n",
       "      <td>0.051083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.017591</td>\n",
       "      <td>0.019987</td>\n",
       "      <td>-0.016805</td>\n",
       "      <td>0.129858</td>\n",
       "      <td>-0.052706</td>\n",
       "      <td>-0.029344</td>\n",
       "      <td>0.066977</td>\n",
       "      <td>-0.084492</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.090267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029835</td>\n",
       "      <td>-0.000642</td>\n",
       "      <td>-0.075613</td>\n",
       "      <td>0.019254</td>\n",
       "      <td>-0.020711</td>\n",
       "      <td>-0.010652</td>\n",
       "      <td>-0.004084</td>\n",
       "      <td>-0.041545</td>\n",
       "      <td>0.014758</td>\n",
       "      <td>-0.033203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.023744  0.060219  0.016482  0.090105 -0.007244 -0.025589  0.034035   \n",
       "1 -0.015911  0.043575 -0.013652  0.100484 -0.005798 -0.015063  0.061395   \n",
       "2 -0.046297  0.020967 -0.013677  0.139245 -0.012362  0.013418  0.070208   \n",
       "3  0.008420  0.075425  0.024882  0.172981 -0.074955 -0.002558  0.046766   \n",
       "4 -0.017591  0.019987 -0.016805  0.129858 -0.052706 -0.029344  0.066977   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0 -0.113440  0.054746  0.114717  ... -0.056137  0.021115 -0.082917  0.063784   \n",
       "1 -0.072637  0.067469  0.103962  ... -0.038242  0.030037 -0.157944  0.021459   \n",
       "2 -0.079559  0.020009  0.104837  ... -0.003211  0.003720 -0.082918  0.050714   \n",
       "3 -0.103122 -0.002265  0.140211  ... -0.073666  0.068075 -0.044182  0.050248   \n",
       "4 -0.084492  0.057343  0.090267  ... -0.029835 -0.000642 -0.075613  0.019254   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.043157 -0.026655 -0.040477 -0.025094  0.054904  0.021000  \n",
       "1 -0.003957 -0.000028 -0.006192 -0.096130  0.038877 -0.055206  \n",
       "2  0.012108 -0.075983  0.002162 -0.033747  0.014359 -0.000162  \n",
       "3  0.045441 -0.017130 -0.008546 -0.096064  0.009728  0.051083  \n",
       "4 -0.020711 -0.010652 -0.004084 -0.041545  0.014758 -0.033203  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bal_w2v_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bootstrap for Confidence intervals for B = 1000, n = len(predrmfr)\n",
    "#default 95% confidence, plot accuracy distribution\n",
    "#test and osr_pred are 1d arrays\n",
    "def confidence_bootstrap(test, ospred, conf = 0.95, b = 1000, acc = True):\n",
    "    sim_acc = []\n",
    "    sim_diff = []\n",
    "    n = len(ospred)\n",
    "    ossample = accuracy_score(test,ospred)\n",
    "    \n",
    "    df_data = {'real':test,'pred':ospred}\n",
    "    sample_data = pd.DataFrame(df_data, columns =['real','pred'])\n",
    "    \n",
    "    #simulation\n",
    "    for i in range(n):\n",
    "        bsample = sample_data.sample(n=len(ospred),replace=True)\n",
    "        sim_acc.append(accuracy_score(bsample['real'],bsample['pred']))\n",
    "        sim_diff.append(accuracy_score(bsample['real'],bsample['pred']) - ossample)\n",
    "    \n",
    "    sim_acc.sort()\n",
    "    sim_diff.sort()\n",
    "   \n",
    "    #onfidence Interval\n",
    "    lower = int(np.floor(n*(1-conf)/2))\n",
    "    upper = int(np.floor(n*(1+conf)/2))\n",
    "    \n",
    "    #Plots\n",
    "    if acc == False:\n",
    "        sns.distplot(sim_diff)\n",
    "        plt.xlabel(\"Difference\")\n",
    "        plt.title(\"Distribution of Difference of OSR2\")\n",
    "    else:\n",
    "        sns.distplot(sim_acc)\n",
    "        plt.xlabel(\"Accuracy\")\n",
    "        plt.title(\"Distribution of Accuracy\")\n",
    "    print(\"Confidence Interval:\", sim_acc[lower],sim_acc[upper])\n",
    "    print(\"Lower and Upper Quantiles:\",sim_diff[lower],sim_diff[upper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MN Naive Bayes Import\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 368  117]\n",
      " [ 233 2282]]\n",
      "Score: 88.33\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.76      0.68       485\n",
      "           1       0.95      0.91      0.93      2515\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.78      0.83      0.80      3000\n",
      "weighted avg       0.90      0.88      0.89      3000\n",
      "\n",
      "f1 score: 0.9287749287749286\n"
     ]
    }
   ],
   "source": [
    "#MN Naive Bayes using Bag of Words\n",
    "mnb.fit(X_balcv,y_balcv)\n",
    "predmnb = mnb.predict(X_testcv)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(f'f1 score: {f1_score(y_test,predmnb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence Interval: 0.872 0.8946666666666667\n",
      "Lower and Upper Quantiles: -0.011333333333333306 0.011333333333333417\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confidence_bootstrap(y_test.values.tolist(),predmnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 410   75]\n",
      " [ 348 2167]]\n",
      "Score: 85.9\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.85      0.66       485\n",
      "           1       0.97      0.86      0.91      2515\n",
      "\n",
      "    accuracy                           0.86      3000\n",
      "   macro avg       0.75      0.85      0.79      3000\n",
      "weighted avg       0.90      0.86      0.87      3000\n",
      "\n",
      "f1 score: 0.911078410763086\n"
     ]
    }
   ],
   "source": [
    "#MN Naive Bayes using Tf-idf\n",
    "mnb.fit(X_baltfidf,y_baltfidf)\n",
    "predmnb = mnb.predict(X_testtfidf)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(f'f1 score: {f1_score(y_test,predmnb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 338  147]\n",
      " [ 654 1861]]\n",
      "Score: 73.3\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.70      0.46       485\n",
      "           1       0.93      0.74      0.82      2515\n",
      "\n",
      "    accuracy                           0.73      3000\n",
      "   macro avg       0.63      0.72      0.64      3000\n",
      "weighted avg       0.83      0.73      0.76      3000\n",
      "\n",
      "f1 score: 0.8229051514481539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_train = scaler.fit_transform(X_bal_w2v_train)\n",
    "scaled_test = scaler.fit_transform(X_bal_w2v_test)\n",
    "#MN Naive Bayes using Word2vec\n",
    "mnb.fit(scaled_train, y_bal_w2v_train)\n",
    "predmnb = mnb.predict(scaled_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(f'f1 score: {f1_score(y_test,predmnb)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Random Forest\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nreview_random_forest = RandomForestClassifier(random_state=6)\\nreview_random_forest.fit(X_bal_w2v_train, y_bal_w2v_train)\\nherro = review_random_forest.predict(X_bal_w2v_test)\\nprint(f\"Random Forest: {review_random_forest.score(X_bal_w2v_train, y_bal_w2v_train)}\")\\n# Random Forest: 0.9998278533310381\\nprint(f\"Random Forest: {review_random_forest.score(X_bal_w2v_test, y_test)}\")\\n# Random Forest: 0.874\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "review_random_forest = RandomForestClassifier(random_state=6)\n",
    "review_random_forest.fit(X_bal_w2v_train, y_bal_w2v_train)\n",
    "herro = review_random_forest.predict(X_bal_w2v_test)\n",
    "print(f\"Random Forest: {review_random_forest.score(X_bal_w2v_train, y_bal_w2v_train)}\")\n",
    "# Random Forest: 0.9998278533310381\n",
    "print(f\"Random Forest: {review_random_forest.score(X_bal_w2v_test, y_test)}\")\n",
    "# Random Forest: 0.874\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"Confusion Matrix for Multinomial Naive Bayes:\")\\nprint(confusion_matrix(y_test,herro))\\nprint(\"Score:\",round(accuracy_score(y_test,herro)*100,2))\\nprint(\"Classification Report:\",classification_report(y_test,herro))\\nprint(f\\'f1 score: {f1_score(y_test,herro)}\\')\\n# Tuning Hyperparameters: n_estimators, max_features, min_sample_leaf\\n# https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,herro))\n",
    "print(\"Score:\",round(accuracy_score(y_test,herro)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,herro))\n",
    "print(f'f1 score: {f1_score(y_test,herro)}')\n",
    "# Tuning Hyperparameters: n_estimators, max_features, min_sample_leaf\n",
    "# https://www.analyticsvidhya.com/blog/2015/06/tuning-random-forest-model/\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression(penalty = 'l1', solver='saga',random_state=6, C =10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression:\n",
      "[[ 318  167]\n",
      " [ 284 2231]]\n",
      "Score: 84.97\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.66      0.59       485\n",
      "           1       0.93      0.89      0.91      2515\n",
      "\n",
      "    accuracy                           0.85      3000\n",
      "   macro avg       0.73      0.77      0.75      3000\n",
      "weighted avg       0.87      0.85      0.86      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "#Lasso Regression using Bag of Words\n",
    "logreg.fit(X_balcv,y_balcv)\n",
    "predlog = logreg.predict(X_testcv)\n",
    "print(\"Confusion Matrix for Logistic Regression:\")\n",
    "print(confusion_matrix(y_test,predlog))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predlog)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predlog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression:\n",
      "[[ 343  142]\n",
      " [ 248 2267]]\n",
      "Score: 87.0\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64       485\n",
      "           1       0.94      0.90      0.92      2515\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.76      0.80      0.78      3000\n",
      "weighted avg       0.88      0.87      0.88      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "#Lasso Regression using Tf-idf\n",
    "logreg.fit(X_baltfidf,y_baltfidf)\n",
    "predlog = logreg.predict(X_testtfidf)\n",
    "print(\"Confusion Matrix for Logistic Regression:\")\n",
    "print(confusion_matrix(y_test,predlog))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predlog)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predlog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Logistic Regression:\n",
      "[[ 385  100]\n",
      " [ 368 2147]]\n",
      "Score: 84.4\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.79      0.62       485\n",
      "           1       0.96      0.85      0.90      2515\n",
      "\n",
      "    accuracy                           0.84      3000\n",
      "   macro avg       0.73      0.82      0.76      3000\n",
      "weighted avg       0.88      0.84      0.86      3000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "#Lasso Regression using Word2vec ##########################WHY DOES SCALED WORK BETTER?\n",
    "logreg.fit(X_bal_w2v_train, y_bal_w2v_train)\n",
    "predlog = logreg.predict(X_bal_w2v_test)\n",
    "print(\"Confusion Matrix for Logistic Regression:\")\n",
    "print(confusion_matrix(y_test,predlog))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predlog)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predlog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Import\n",
    "import xgboost as xgb#!pip install hyperopt\n",
    "import hyperopt as hyp\n",
    "from hyperopt import fmin, tpe, hp, anneal, Trials\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "random_state = 123\n",
    "n_iter=20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_mse_cv(params, random_state=123, cv=5, X=X_balcv, y=y_balcv):\n",
    "    # the function gets a set of variable parameters in \"param\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'learning_rate': params['learning_rate']}\n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = xgb.XGBClassifier(random_state=random_state, **params)\n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'n_estimators': hp.quniform('n_estimators', 30, 2000, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "       'learning_rate': hp.loguniform('learning_rate', -5, 0)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [19:21<00:00, 58.07s/trial, best loss: 0.11187855783258485]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=gb_mse_cv, # function to optimize\n",
    "          space=space, \n",
    "          algo=hyp.rand.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=n_iter, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.RandomState(random_state) # fixing random state for the reproducibility\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:38:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best MSE 0.112 params {'learning_rate': 0.008540588799230704, 'max_depth': 5.0, 'n_estimators': 1543.0}\n"
     ]
    }
   ],
   "source": [
    "# computing the score on the test set\n",
    "model = xgb.XGBClassifier(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                      max_depth=int(best['max_depth']),learning_rate=best['learning_rate'])\n",
    "model.fit(X_balcv,y_balcv)\n",
    "rand_test_score=mean_squared_error(y_test, model.predict(X_testcv))\n",
    "xgb_BoW_predictions = model.predict(X_testcv)\n",
    "\n",
    "print(\"Best MSE {:.3f} params {}\".format( gb_mse_cv(best), best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[ 150  335]\n",
      " [  34 2481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.31      0.45       485\n",
      "           1       0.88      0.99      0.93      2515\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.85      0.65      0.69      3000\n",
      "weighted avg       0.87      0.88      0.85      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9307822172200337"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,xgb_BoW_predictions))\n",
    "print(classification_report(y_test, xgb_BoW_predictions))\n",
    "f1_score(y_test, xgb_BoW_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:40:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.46      0.58       485\n",
      "           1       0.90      0.98      0.94      2515\n",
      "\n",
      "    accuracy                           0.89      3000\n",
      "   macro avg       0.85      0.72      0.76      3000\n",
      "weighted avg       0.89      0.89      0.88      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9386819484240688"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost using Bag of Words\n",
    "model = xgb.XGBClassifier(random_state = 123)\n",
    "model.fit(X_balcv,y_balcv)\n",
    "from sklearn.metrics import f1_score\n",
    "xgb_predictions = model.predict(X_testcv)\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "f1_score(y_test, xgb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_mse_cv1(params, random_state=123, cv=5, X=X_baltfidf, y=y_baltfidf):\n",
    "    # the function gets a set of variable parameters in \"param\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'learning_rate': params['learning_rate']}\n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = xgb.XGBClassifier(random_state=random_state, **params)\n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'n_estimators': hp.quniform('n_estimators', 30, 2000, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "       'learning_rate': hp.loguniform('learning_rate', -5, 0)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [49:53<00:00, 149.69s/trial, best loss: 0.08081569250990803] \n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=gb_mse_cv1, # function to optimize\n",
    "          space=space, \n",
    "          algo=hyp.rand.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=n_iter, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.RandomState(random_state) # fixing random state for the reproducibility\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best MSE 0.116 params {'learning_rate': 0.022054333903620153, 'max_depth': 13.0, 'n_estimators': 1464.0}\n"
     ]
    }
   ],
   "source": [
    "# computing the score on the test set\n",
    "model = xgb.XGBClassifier(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                      max_depth=int(best['max_depth']),learning_rate=best['learning_rate'])\n",
    "model.fit(X_baltfidf,y_baltfidf)\n",
    "rand_test_score=mean_squared_error(y_test, model.predict(X_testtfidf))\n",
    "xgb_tfidf_predictions = model.predict(X_testtfidf)\n",
    "\n",
    "print(\"Best MSE {:.3f} params {}\".format( gb_mse_cv(best), best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.53      0.59       485\n",
      "           1       0.91      0.95      0.93      2515\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.79      0.74      0.76      3000\n",
      "weighted avg       0.87      0.88      0.88      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9304229195088677"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb_tfidf_predictions))\n",
    "f1_score(y_test, xgb_tfidf_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[07:33:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.54      0.58       485\n",
      "           1       0.91      0.94      0.93      2515\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.77      0.74      0.76      3000\n",
      "weighted avg       0.87      0.88      0.87      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9266954135633084"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost using Tf-idf\n",
    "model = xgb.XGBClassifier(random_state = 123)\n",
    "model.fit(X_baltfidf,y_baltfidf)\n",
    "from sklearn.metrics import f1_score\n",
    "xgb_predictions = model.predict(X_testtfidf)\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "f1_score(y_test, xgb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gb_mse_cv2(params, random_state=123, cv=5, X=X_bal_w2v_train, y=y_bal_w2v_train):\n",
    "    # the function gets a set of variable parameters in \"param\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'learning_rate': params['learning_rate']}\n",
    "    # we use this params to create a new LGBM Regressor\n",
    "    model = xgb.XGBClassifier(random_state=random_state, **params)\n",
    "    # and then conduct the cross validation with the same folds as before\n",
    "    score = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={'n_estimators': hp.quniform('n_estimators', 30, 2000, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 2, 20, 1),\n",
    "       'learning_rate': hp.loguniform('learning_rate', -5, 0)\n",
    "      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [1:18:59<00:00, 236.97s/trial, best loss: 0.04785524238272813]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best=fmin(fn=gb_mse_cv2, # function to optimize\n",
    "          space=space, \n",
    "          algo=hyp.rand.suggest, # optimization algorithm, hyperotp will select its parameters automatically\n",
    "          max_evals=n_iter, # maximum number of iterations\n",
    "          trials=trials, # logging\n",
    "          rstate=np.random.RandomState(random_state) # fixing random state for the reproducibility\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:52:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best MSE 0.120 params {'learning_rate': 0.17771918355622215, 'max_depth': 13.0, 'n_estimators': 842.0}\n"
     ]
    }
   ],
   "source": [
    "# computing the score on the test set\n",
    "model = xgb.XGBClassifier(random_state=random_state, n_estimators=int(best['n_estimators']),\n",
    "                      max_depth=int(best['max_depth']),learning_rate=best['learning_rate'])\n",
    "\n",
    "\n",
    "model.fit(X_bal_w2v_train,y_bal_w2v_train)\n",
    "rand_test_score=mean_squared_error(y_test, model.predict(X_bal_w2v_test))\n",
    "xgb_w2v_predictions = model.predict(X_bal_w2v_test)\n",
    "\n",
    "print(\"Best MSE {:.3f} params {}\".format( gb_mse_cv(best), best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.58      0.61       485\n",
      "           1       0.92      0.94      0.93      2515\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.78      0.76      0.77      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.929893658920835"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(y_test, xgb_w2v_predictions))\n",
    "f1_score(y_test, xgb_w2v_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:53:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Steven Johannemann\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.59      0.59       485\n",
      "           1       0.92      0.92      0.92      2515\n",
      "\n",
      "    accuracy                           0.87      3000\n",
      "   macro avg       0.76      0.76      0.76      3000\n",
      "weighted avg       0.87      0.87      0.87      3000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9225883287018658"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost using Word2vec\n",
    "model = xgb.XGBClassifier(random_state = 123)\n",
    "model.fit(X_bal_w2v_train,y_bal_w2v_train)\n",
    "from sklearn.metrics import f1_score\n",
    "xgb_predictions = model.predict(X_bal_w2v_test)\n",
    "print(classification_report(y_test, xgb_predictions))\n",
    "f1_score(y_test, xgb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02374415  0.06021875  0.01648218 ... -0.02509382  0.05490401\n",
      "   0.02100026]\n",
      " [-0.0159111   0.04357529 -0.01365153 ... -0.09613037  0.03887717\n",
      "  -0.0552063 ]\n",
      " [-0.04629723  0.02096696 -0.01367742 ... -0.03374745  0.0143588\n",
      "  -0.00016174]\n",
      " ...\n",
      " [ 0.03773635  0.04661243 -0.00347702 ... -0.03197458  0.03983109\n",
      "  -0.01870567]\n",
      " [-0.00652099  0.02587429  0.0226821  ... -0.04240371 -0.01293024\n",
      "  -0.00561666]\n",
      " [ 0.00127035  0.04852371 -0.00530757 ... -0.01893766  0.05268669\n",
      "  -0.00287938]]\n"
     ]
    }
   ],
   "source": [
    "print(X_bal_w2v_train.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = DataFrame(xgb_BoW_predictions, columns =['predictions'])\n",
    "frames = [X_test.reset_index(), y_test.reset_index(), results]\n",
    "result = pd.concat(frames, axis = 1)\n",
    "results_0 = result.loc[result['predictions'] == 0]\n",
    "#results_0.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     This place used to be amazing.  My favorite me...\n",
       "31    Went into the location and waited minutes for ...\n",
       "68    What was Dunkin Donuts thinking when they took...\n",
       "76    We ordered $ worth of pizza for takeout and it...\n",
       "80                   Poor service-small portions-pricey\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_text = results_0['text']\n",
    "LDA_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_nan_removed = results_0[~results_0.text.isnull()]\n",
    "#print(result_nan_removed)\n",
    "#result_nan_removed['attitude'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA model https://shichaoji.com/tag/topic-modeling-python-lda-visualization-gensim-pyldavis-nltk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Steven\n",
      "[nltk_data]     Johannemann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Steven\n",
      "[nltk_data]     Johannemann\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "punctuation = set(string.punctuation) \n",
    "lemmatize = WordNetLemmatizer()\n",
    "\n",
    "def cleaning(article):\n",
    "    one = \" \".join([i for i in article.lower().split() if i not in stopwords])\n",
    "    two = \"\".join(i for i in one if i not in punctuation)\n",
    "    three = \" \".join(lemmatize.lemmatize(i) for i in two.split())\n",
    "    return three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     This place used to be amazing.  My favorite me...\n",
       "31    Went into the location and waited minutes for ...\n",
       "68    What was Dunkin Donuts thinking when they took...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_text.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 622,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data = pd.read_csv('yelp_neg_rev.csv', error_bad_lines=False);\n",
    "#data_text = data[['text']]\n",
    "#text = data_text.applymap(cleaning)['text']\n",
    "text = LDA_text.to_frame().applymap(cleaning)['text']\n",
    "text_list = [i.split() for i in text]\n",
    "len(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['place',\n",
       " 'used',\n",
       " 'amazing',\n",
       " 'favorite',\n",
       " 'memory',\n",
       " 'past',\n",
       " 'year',\n",
       " 'going',\n",
       " 'seafood',\n",
       " 'place',\n",
       " 'parent',\n",
       " 'anymore',\n",
       " 'went',\n",
       " 'wife',\n",
       " 'th',\n",
       " 'birthday',\n",
       " 'dad',\n",
       " 'decided',\n",
       " 'join',\n",
       " 'u',\n",
       " 'wife',\n",
       " 'ordered',\n",
       " 'steak',\n",
       " 'shrimp',\n",
       " 'dad',\n",
       " 'ordered',\n",
       " 'steak',\n",
       " 'ordered',\n",
       " 'crab',\n",
       " 'stuffed',\n",
       " 'lobster',\n",
       " 'crab',\n",
       " 'stuffed',\n",
       " 'lobster',\n",
       " 'many',\n",
       " 'time',\n",
       " 'before',\n",
       " 'craving',\n",
       " 'it',\n",
       " 'got',\n",
       " 'appetizer',\n",
       " 'dad',\n",
       " 'got',\n",
       " 'snail',\n",
       " 'wife',\n",
       " 'shared',\n",
       " 'steamer',\n",
       " 'dad',\n",
       " 'happy',\n",
       " 'snail',\n",
       " 'again',\n",
       " 'go',\n",
       " 'wrong',\n",
       " 'snail',\n",
       " 'doused',\n",
       " 'garlic',\n",
       " 'butter',\n",
       " 'steamer',\n",
       " 'steamed',\n",
       " 'little',\n",
       " 'neck',\n",
       " 'clam',\n",
       " 'garlic',\n",
       " 'broth',\n",
       " 'long',\n",
       " 'neck',\n",
       " 'clam',\n",
       " 'like',\n",
       " 'rest',\n",
       " 'world',\n",
       " 'call',\n",
       " 'steamer',\n",
       " 'argue',\n",
       " 'server',\n",
       " 'wrong',\n",
       " 'clam',\n",
       " 'food',\n",
       " 'came',\n",
       " 'first',\n",
       " 'time',\n",
       " 'life',\n",
       " 'asking',\n",
       " 'server',\n",
       " 'take',\n",
       " 'back',\n",
       " 'meal',\n",
       " 'even',\n",
       " 'tried',\n",
       " 'it',\n",
       " 'looked',\n",
       " 'dry',\n",
       " 'cooked',\n",
       " 'told',\n",
       " 'server',\n",
       " 'ive',\n",
       " 'dish',\n",
       " 'many',\n",
       " 'time',\n",
       " 'way',\n",
       " 'supposed',\n",
       " 'be',\n",
       " 'told',\n",
       " 'supposed',\n",
       " 'look',\n",
       " 'like',\n",
       " 'begged',\n",
       " 'try',\n",
       " 'it',\n",
       " 'took',\n",
       " 'one',\n",
       " 'bite',\n",
       " 'even',\n",
       " 'swallow',\n",
       " 'dry',\n",
       " 'course',\n",
       " 'server',\n",
       " 'gone',\n",
       " 'point',\n",
       " 'come',\n",
       " 'back',\n",
       " 'minute',\n",
       " 'ask',\n",
       " 'wa',\n",
       " 'waiting',\n",
       " 'server',\n",
       " 'return',\n",
       " 'told',\n",
       " 'family',\n",
       " 'going',\n",
       " 'get',\n",
       " 'steak',\n",
       " 'shook',\n",
       " 'head',\n",
       " 'told',\n",
       " 'to',\n",
       " 'took',\n",
       " 'one',\n",
       " 'bite',\n",
       " 'dad',\n",
       " 'steak',\n",
       " 'spat',\n",
       " 'out',\n",
       " 'screw',\n",
       " 'steak',\n",
       " 'bad',\n",
       " 'tasted',\n",
       " 'like',\n",
       " 'beef',\n",
       " 'jerky',\n",
       " 'butter',\n",
       " 'dad',\n",
       " 'wife',\n",
       " 'would',\n",
       " 'complained',\n",
       " 'too',\n",
       " 'wife',\n",
       " 'birthday',\n",
       " 'already',\n",
       " 'stealing',\n",
       " 'thunder',\n",
       " 'swapped',\n",
       " 'meal',\n",
       " 'steamed',\n",
       " 'lobster',\n",
       " 'screw',\n",
       " 'steamed',\n",
       " 'lobster',\n",
       " 'fortunately',\n",
       " 'came',\n",
       " 'fine',\n",
       " 'left',\n",
       " 'hungry',\n",
       " 'poorer',\n",
       " 'used',\n",
       " 'mind',\n",
       " 'paying',\n",
       " 'money',\n",
       " 'charged',\n",
       " 'now',\n",
       " 'worth',\n",
       " 'it',\n",
       " 'really',\n",
       " 'hoping',\n",
       " 'people',\n",
       " 'stop',\n",
       " 'coming',\n",
       " 'close',\n",
       " 'down']"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO,\n",
    "                   filename='running.log',filemode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(3951 unique tokens: ['again', 'already', 'amazing', 'anymore', 'appetizer']...)\n"
     ]
    }
   ],
   "source": [
    "# Importing Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# Creating the term dictionary of our courpus, where every unique term is assigned an index. dictionary = corpora.Dictionary(doc_clean)\n",
    "dictionary = corpora.Dictionary(text_list)\n",
    "dictionary.save('dictionary.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184\n",
      "[(8, 1), (23, 1), (46, 1), (68, 1), (73, 1), (75, 1), (80, 3), (83, 1), (100, 1), (118, 1), (122, 1), (149, 1), (160, 1), (184, 1), (198, 1), (202, 1), (225, 1), (398, 1), (463, 1), (503, 1), (517, 1), (528, 1), (550, 2), (553, 1), (604, 1), (632, 1), (734, 1), (827, 1), (915, 1), (1000, 1), (1206, 1), (1470, 1), (1517, 1), (1534, 1), (1536, 1), (1823, 1), (1905, 1), (1915, 1), (2345, 2), (2618, 1), (2724, 1), (2725, 1), (2726, 1), (2727, 2), (2728, 1), (2729, 1)]\n"
     ]
    }
   ],
   "source": [
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in text_list]\n",
    "corpora.MmCorpus.serialize('corpus.mm', doc_term_matrix)\n",
    "\n",
    "print(len(doc_term_matrix))\n",
    "print (doc_term_matrix[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used: 7.14s\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Training LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=3, id2word=dictionary, random_state=6, passes=50)\n",
    "print('used: {:.2f}s'.format(time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.009*\"food\" + 0.007*\"u\" + 0.006*\"one\" + 0.006*\"like\"'), (1, '0.010*\"food\" + 0.009*\"like\" + 0.008*\"time\" + 0.007*\"one\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodel.print_topics(num_topics=2, num_words=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.009*\"food\" + 0.007*\"u\" + 0.006*\"one\" + 0.006*\"like\" + 0.006*\"get\" + 0.006*\"would\" + 0.006*\"place\" + 0.005*\"service\" + 0.005*\"good\" + 0.005*\"time\"\n",
      "1\n",
      "0.010*\"food\" + 0.009*\"like\" + 0.008*\"time\" + 0.007*\"one\" + 0.007*\"u\" + 0.007*\"place\" + 0.006*\"would\" + 0.006*\"get\" + 0.006*\"good\" + 0.006*\"back\"\n",
      "2\n",
      "0.007*\"one\" + 0.007*\"place\" + 0.007*\"me\" + 0.006*\"im\" + 0.005*\"food\" + 0.005*\"pizza\" + 0.005*\"time\" + 0.005*\"like\" + 0.005*\"get\" + 0.005*\"service\"\n"
     ]
    }
   ],
   "source": [
    "for i in ldamodel.print_topics(): \n",
    "    for j in i: print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldamodel.save('topic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "loading = LdaModel.load('topic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, '0.010*\"food\" + 0.009*\"like\" + 0.008*\"time\" + 0.007*\"one\"'), (2, '0.007*\"one\" + 0.007*\"place\" + 0.007*\"me\" + 0.006*\"im\"')]\n"
     ]
    }
   ],
   "source": [
    "print(loading.print_topics(num_topics=2, num_words=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_new(doc):\n",
    "    one = cleaning(doc).split()\n",
    "    two = dictionary.doc2bow(one)\n",
    "    return two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(171, 1), (3188, 1), (3625, 1)]"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_new('new article that to be classified by trained model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.42609444), (1, 0.09946298), (2, 0.4744426)]"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "belong = loading[(pre_new('new article that to be classified by trained model!'))]\n",
    "belong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prob</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.474443</td>\n",
       "      <td>0.007*\"one\" + 0.007*\"place\" + 0.007*\"me\" + 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.426094</td>\n",
       "      <td>0.009*\"food\" + 0.007*\"u\" + 0.006*\"one\" + 0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.099463</td>\n",
       "      <td>0.010*\"food\" + 0.009*\"like\" + 0.008*\"time\" + 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      prob                                              topic\n",
       "2   2  0.474443  0.007*\"one\" + 0.007*\"place\" + 0.007*\"me\" + 0.0...\n",
       "0   0  0.426094  0.009*\"food\" + 0.007*\"u\" + 0.006*\"one\" + 0.006...\n",
       "1   1  0.099463  0.010*\"food\" + 0.009*\"like\" + 0.008*\"time\" + 0..."
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new = pd.DataFrame(belong,columns=['id','prob']).sort_values('prob',ascending=False)\n",
    "new['topic'] = new['id'].apply(loading.print_topic)\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.007*\"one\" + 0.007*\"place\" + 0.007*\"me\" + 0.0...\n",
       "0    0.009*\"food\" + 0.007*\"u\" + 0.006*\"one\" + 0.006...\n",
       "1    0.010*\"food\" + 0.009*\"like\" + 0.008*\"time\" + 0...\n",
       "Name: topic, dtype: object"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new['topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = gensim.corpora.Dictionary.load('dictionary.dict')\n",
    "c = gensim.corpora.MmCorpus('corpus.mm')\n",
    "lda = gensim.models.LdaModel.load('topic.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el2960020730177611205131982802\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el2960020730177611205131982802_data = {\"mdsDat\": {\"x\": [-0.037343737177299274, -0.03982006190088133, 0.0771637990781806], \"y\": [0.054879715256503654, -0.05371801658648668, -0.0011616986700169925], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [48.58410439262368, 31.50486352603285, 19.911032081343475]}, \"tinfo\": {\"Term\": [\"me\", \"pizza\", \"nail\", \"im\", \"no\", \"bag\", \"you\", \"guy\", \"polish\", \"place\", \"employee\", \"slice\", \"thai\", \"waiter\", \"were\", \"one\", \"server\", \"rib\", \"cash\", \"say\", \"pedi\", \"coffee\", \"pasta\", \"restaurant\", \"donut\", \"flight\", \"burger\", \"plane\", \"lost\", \"topping\", \"thai\", \"pasta\", \"game\", \"noodle\", \"desk\", \"massage\", \"online\", \"simple\", \"flirting\", \"simply\", \"gym\", \"cousin\", \"curry\", \"root\", \"certainly\", \"happy\", \"brio\", \"elephant\", \"promised\", \"fitness\", \"certain\", \"shed\", \"space\", \"excited\", \"sampler\", \"tempura\", \"mixed\", \"young\", \"four\", \"mousse\", \"evening\", \"roll\", \"manager\", \"server\", \"mom\", \"chicken\", \"asking\", \"item\", \"boyfriend\", \"main\", \"since\", \"getting\", \"table\", \"like\", \"got\", \"time\", \"food\", \"long\", \"even\", \"told\", \"left\", \"u\", \"back\", \"would\", \"good\", \"one\", \"minute\", \"another\", \"order\", \"drink\", \"place\", \"get\", \"went\", \"go\", \"ordered\", \"said\", \"service\", \"ive\", \"really\", \"going\", \"never\", \"asked\", \"came\", \"slider\", \"sapporo\", \"lee\", \"gyro\", \"reservation\", \"blah\", \"wasted\", \"direction\", \"cuz\", \"ring\", \"attached\", \"insurance\", \"self\", \"toast\", \"stale\", \"onion\", \"pot\", \"de\", \"creme\", \"moscato\", \"peach\", \"reseated\", \"irritating\", \"andor\", \"jewish\", \"opinion\", \"chompie\", \"awhile\", \"skirt\", \"co\", \"music\", \"coffee\", \"absolutely\", \"burger\", \"dont\", \"hungry\", \"challenge\", \"fry\", \"salsa\", \"leave\", \"waiter\", \"sweet\", \"restaurant\", \"fish\", \"tasted\", \"thing\", \"meal\", \"bill\", \"food\", \"oh\", \"u\", \"say\", \"would\", \"get\", \"order\", \"service\", \"ordered\", \"made\", \"two\", \"never\", \"one\", \"good\", \"place\", \"like\", \"came\", \"wanted\", \"it\", \"time\", \"people\", \"back\", \"said\", \"table\", \"well\", \"come\", \"could\", \"im\", \"minute\", \"asked\", \"go\", \"take\", \"polish\", \"pedi\", \"plane\", \"lost\", \"topping\", \"nail\", \"mama\", \"wm\", \"matthew\", \"movie\", \"fell\", \"mani\", \"lax\", \"charcoal\", \"finger\", \"bagging\", \"fucking\", \"gallo\", \"blanco\", \"very\", \"taxi\", \"sorbet\", \"wedding\", \"bride\", \"skill\", \"building\", \"maam\", \"mechanical\", \"tokyo\", \"agent\", \"plenty\", \"no\", \"rib\", \"pizza\", \"me\", \"bag\", \"buck\", \"you\", \"employee\", \"slice\", \"im\", \"lady\", \"guy\", \"didnt\", \"thanks\", \"cash\", \"avoid\", \"place\", \"one\", \"donut\", \"customer\", \"time\", \"going\", \"service\", \"line\", \"it\", \"get\", \"go\", \"food\", \"like\", \"say\", \"another\", \"back\", \"said\", \"right\", \"u\", \"good\", \"told\", \"even\", \"would\", \"minute\"], \"Freq\": [45.0, 30.0, 11.0, 60.0, 14.0, 16.0, 15.0, 36.0, 7.0, 117.0, 18.0, 16.0, 18.0, 22.0, 14.0, 127.0, 46.0, 8.0, 11.0, 43.0, 5.0, 13.0, 17.0, 46.0, 10.0, 11.0, 11.0, 5.0, 5.0, 5.0, 17.664575687614786, 16.52232020376951, 8.976520874184642, 7.238816157840264, 7.216238424231782, 6.3701376154896066, 6.370125909006751, 6.370019023728503, 6.355377776518656, 6.31844127822141, 5.501318086367165, 5.501315541479587, 5.501308415794371, 5.50128500282866, 5.492521427967395, 8.570017837818813, 4.632530113850683, 4.632519934300373, 4.632518916345342, 4.632511281682611, 4.632497539289693, 4.632485832806837, 4.632484305874291, 4.632463437796157, 4.632451731313301, 4.632444605628084, 4.627952879054112, 4.621427278328344, 4.616688697659371, 7.578733737678018, 8.983530512527617, 15.915994630742452, 19.423245696798656, 37.415209973730526, 8.980365690336459, 22.018652346395186, 8.109939828175213, 20.012861537993018, 13.338353332345687, 6.672896782833372, 25.087501737236384, 15.070714293755204, 49.96089495690748, 78.86076451139546, 41.62747124533213, 66.60603957879877, 86.3029360188318, 21.622757419406668, 41.276785737177214, 37.422486316291604, 25.09669590707573, 63.46623057866161, 50.08245100306073, 56.11374905309034, 50.10526948303403, 64.52510740183358, 38.06253979335842, 28.011115411994865, 39.47573011641554, 31.002087171149896, 57.52833193862977, 52.577996264123165, 31.228244204461248, 36.989859499967054, 35.694857827820876, 34.62343572684774, 39.05545720234634, 27.877262469067997, 29.728089983111897, 29.778440074851687, 29.770326973255187, 28.075985614295824, 27.716427610091333, 5.9409903482201605, 5.130729881082439, 5.1306450577907, 4.320519251754259, 4.320518921702541, 4.320497138289098, 4.258688682955827, 3.5103010312365472, 3.5102927799435766, 3.5102855188057625, 3.51026934627154, 3.5102488830649725, 3.5102419519788772, 3.5102294100135616, 3.510207626600119, 6.7659731023279415, 2.7000582218657825, 2.7000580568399233, 2.7000580568399233, 2.7000580568399233, 2.7000580568399233, 2.7000498055469526, 2.700032477831714, 2.700030002443823, 2.7000291773145255, 2.7000219161767114, 2.700010529392412, 2.7000095392372554, 2.7000070638493643, 2.7000040933838947, 4.050890761195232, 11.076391781330896, 6.6704785784158895, 9.194371530331168, 5.114831949889913, 6.94650941221675, 3.3200592205038713, 10.879361466845358, 6.119869138377013, 9.714680242271285, 14.363329321695185, 7.573885581537919, 24.783050203245143, 8.28786270115559, 12.498930531963701, 18.416705042281475, 15.282305524497785, 10.886867503034953, 50.43257330206854, 12.482860973877386, 39.41453070400588, 19.360345349928682, 35.062162451539834, 35.51304478442441, 26.694453638565285, 29.89622727381685, 25.644828443174784, 16.687878296575935, 17.5118405307691, 22.047545912009927, 36.06682668158466, 29.110173459841437, 33.985612957134194, 35.89952214510368, 20.100286978163144, 16.880604736647953, 21.410626627290554, 28.772052636591148, 17.71893610247203, 23.65260194294795, 20.573071543109165, 21.934315728934912, 16.395037928735146, 15.82330913931188, 17.708655651533963, 18.300620571942034, 17.933304693851056, 16.865160956620535, 17.445477691767714, 16.704808629544956, 6.8509287587596575, 5.378037189427121, 4.65036479478685, 4.650347273037868, 4.64674029585457, 10.487611981534736, 3.914966143214508, 3.181680739724747, 3.1816730218115046, 3.1815568359283737, 3.1813932996045415, 3.1758603901789693, 2.447333601683575, 2.4473333930913252, 2.447331515761077, 2.447327761100581, 2.4473273439160814, 2.4473244236245844, 2.4473242150323347, 2.4473106565360987, 2.447310239351599, 2.4472973066321124, 2.447273318523387, 2.4472560053666546, 2.446992761947425, 2.446974823013943, 2.4439644196650323, 1.7129835433509064, 1.7129833347586567, 1.7129833347586567, 3.9227395419950306, 10.525909518595435, 6.121296014155898, 19.08107116723523, 23.406126336052907, 9.811593702893457, 3.92309122852817, 9.068748308003757, 9.06950508068598, 8.34414138506634, 20.673678000564916, 4.657653425178871, 13.051566172597637, 4.652205412798962, 3.9295980551679928, 6.121905937894272, 5.40462185447784, 26.316335318070486, 26.593926546609627, 5.4135579464586705, 10.537112591146938, 18.96273261208667, 12.951016364510819, 16.26283634873127, 6.86973376726236, 13.10026662233966, 16.63233832874009, 13.137719777973226, 19.39980179364615, 17.56599890751998, 10.537983672382046, 10.521997162358451, 13.335617920297146, 11.568921664034109, 9.4224423329548, 12.705352265723917, 11.307334467267546, 9.838900931497436, 9.79668352887876, 10.380770196825376, 9.585907735422055], \"Total\": [45.0, 30.0, 11.0, 60.0, 14.0, 16.0, 15.0, 36.0, 7.0, 117.0, 18.0, 16.0, 18.0, 22.0, 14.0, 127.0, 46.0, 8.0, 11.0, 43.0, 5.0, 13.0, 17.0, 46.0, 10.0, 11.0, 11.0, 5.0, 5.0, 5.0, 18.17951913565984, 17.291730139172433, 9.491450818184628, 7.753816129322792, 7.750731325778823, 6.885031679755073, 6.8850291125594065, 6.885010584505917, 6.883838058823314, 6.878367017424532, 6.016219143267588, 6.01621869965286, 6.016218234240958, 6.016213317184644, 6.015493411147668, 9.463445538267454, 5.147412375315954, 5.147410188621408, 5.147410091671223, 5.147408080424385, 5.1474067659503815, 5.147403752360311, 5.147403950947319, 5.147399437726426, 5.147397483925112, 5.14739557652467, 5.14702258684506, 5.146493723456406, 5.144813356349712, 8.58628844936764, 10.226385330008133, 18.643881603780727, 23.009138615720577, 46.22478841334042, 10.301162772870065, 26.498840469512153, 9.356840527657818, 24.742929487630914, 16.19050653156951, 7.714964326111202, 33.67682415988257, 19.320009472890273, 76.6101260210635, 132.32628556401912, 63.72268665224269, 114.3408248274766, 156.1353111145465, 30.275084143616652, 65.77665812345623, 59.8408002312856, 36.928601020309664, 115.58611354839141, 87.07067086630582, 101.55668170145555, 90.52277741014302, 127.18586063002786, 65.58175222263154, 44.55150005063873, 70.29283727480171, 51.69065573189766, 117.83028021383444, 104.72337937728766, 53.15025660948375, 67.57305696970799, 68.14068263418605, 66.76542893399102, 85.21452082489446, 46.4417700232503, 52.92234100350673, 54.95267232707199, 56.60598824715011, 49.24924652730244, 51.69966348986484, 6.475414859025311, 5.665172993786812, 5.665161197672953, 4.854937464117981, 4.854937910550135, 4.854934695603686, 4.850963837554916, 4.04469885090241, 4.044698242542859, 4.0446972855835375, 4.044694505287203, 4.044691551481834, 4.044691202050074, 4.044689217533779, 4.044686350053411, 8.026318563736735, 3.23445432741163, 3.2344542286192466, 3.2344542374820877, 3.2344546625004456, 3.2344547521966662, 3.2344530997303904, 3.2344510176448833, 3.2344504164614634, 3.234450213468647, 3.2344495282481045, 3.2344480601184777, 3.2344492989532396, 3.234447198338284, 3.234446906770816, 4.873582019743847, 13.65197707770762, 8.159086789655536, 11.451937739829527, 6.399958407401201, 8.906005890674166, 4.057571076198551, 15.405275008080178, 8.09331472169981, 14.020795723931387, 22.371508525606206, 10.700290837182658, 46.1466861890996, 12.386317210965908, 20.530498779440254, 36.331632268192614, 28.98883626960951, 18.624635574712187, 156.1353111145465, 23.30427459721436, 115.58611354839141, 43.58409615534193, 101.55668170145555, 104.72337937728766, 70.29283727480171, 85.21452082489446, 68.14068263418605, 36.49718615327164, 39.80330645139216, 56.60598824715011, 127.18586063002786, 90.52277741014302, 117.83028021383444, 132.32628556401912, 51.69966348986484, 39.494285163982056, 61.211646048062185, 114.3408248274766, 47.72776582803112, 87.07067086630582, 66.76542893399102, 76.6101260210635, 41.8274878466302, 38.37536820558181, 52.10506323247534, 60.91849768794002, 65.58175222263154, 49.24924652730244, 67.57305696970799, 49.477338667413015, 7.4134004183686955, 5.94523820891733, 5.210068773992217, 5.2100692016872, 5.210619686472431, 11.959068881317847, 4.475811392685593, 3.7413813517590984, 3.7413815778961794, 3.7413958215696006, 3.741402306280865, 3.7421029065028986, 3.00703439643327, 3.007034548188015, 3.0070347907965775, 3.007034847368277, 3.0070345725293497, 3.0070345573436406, 3.007034572186963, 3.00703491488155, 3.007034841427033, 3.007035310587897, 3.007033669211628, 3.0070329155706266, 3.0070808171486356, 3.0070808024475357, 3.007546189119815, 2.27268293016832, 2.2726828117968783, 2.2726828324251107, 5.284488156751474, 14.500343622152437, 8.414829110231066, 30.77161691370308, 45.82934898561341, 16.30450954451411, 5.342032115131043, 15.577042900487296, 18.007374205237486, 16.579146037516935, 60.91849768794002, 7.696420777721715, 36.20244120899152, 7.815050634628637, 6.09405235439387, 11.889992193321198, 10.124933749532373, 117.83028021383444, 127.18586063002786, 10.28196673968883, 35.63234342223013, 114.3408248274766, 54.95267232707199, 85.21452082489446, 16.672339443501166, 61.211646048062185, 104.72337937728766, 67.57305696970799, 156.1353111145465, 132.32628556401912, 43.58409615534193, 44.55150005063873, 87.07067086630582, 66.76542893399102, 37.68368037661583, 115.58611354839141, 90.52277741014302, 59.8408002312856, 65.77665812345623, 101.55668170145555, 65.58175222263154], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.2046, -6.2714, -6.8815, -7.0967, -7.0998, -7.2245, -7.2245, -7.2245, -7.2268, -7.2327, -7.3712, -7.3712, -7.3712, -7.3712, -7.3728, -6.9279, -7.543, -7.543, -7.543, -7.543, -7.543, -7.543, -7.543, -7.5431, -7.5431, -7.5431, -7.544, -7.5454, -7.5465, -7.0508, -6.8807, -6.3088, -6.1097, -5.4541, -6.8811, -5.9843, -6.9831, -6.0798, -6.4855, -7.1781, -5.8538, -6.3634, -5.1649, -4.7085, -5.3474, -4.8773, -4.6183, -6.0024, -5.3558, -5.4539, -5.8534, -4.9256, -5.1625, -5.0488, -5.162, -4.9091, -5.4369, -5.7435, -5.4005, -5.6421, -5.0239, -5.1138, -5.6348, -5.4655, -5.5011, -5.5316, -5.4112, -5.7483, -5.684, -5.6824, -5.6826, -5.7412, -5.7541, -6.8611, -7.0077, -7.0078, -7.1796, -7.1796, -7.1796, -7.194, -7.3873, -7.3873, -7.3873, -7.3873, -7.3873, -7.3873, -7.3873, -7.3873, -6.7311, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.6497, -7.2441, -6.2382, -6.7453, -6.4244, -7.0108, -6.7047, -7.443, -6.2561, -6.8314, -6.3693, -5.9783, -6.6183, -5.4328, -6.5282, -6.1173, -5.7297, -5.9163, -6.2554, -4.7224, -6.1186, -4.9689, -5.6798, -5.0859, -5.0731, -5.3585, -5.2453, -5.3986, -5.8283, -5.7801, -5.5498, -5.0576, -5.2719, -5.1171, -5.0623, -5.6423, -5.8168, -5.5791, -5.2836, -5.7684, -5.4795, -5.619, -5.5549, -5.846, -5.8815, -5.7689, -5.7361, -5.7563, -5.8177, -5.7839, -5.8273, -6.2597, -6.5018, -6.6472, -6.6472, -6.648, -5.8339, -6.8193, -7.0267, -7.0267, -7.0267, -7.0268, -7.0285, -7.2891, -7.2891, -7.2891, -7.2891, -7.2891, -7.2891, -7.2891, -7.2891, -7.2891, -7.2891, -7.2891, -7.2892, -7.2893, -7.2893, -7.2905, -7.6459, -7.6459, -7.6459, -6.8173, -5.8303, -6.3723, -5.2354, -5.0311, -5.9006, -6.8172, -5.9793, -5.9792, -6.0626, -5.1553, -6.6456, -5.6152, -6.6468, -6.8156, -6.3722, -6.4969, -4.9139, -4.9034, -6.4952, -5.8292, -5.2416, -5.6229, -5.3952, -6.257, -5.6115, -5.3728, -5.6086, -5.2189, -5.3182, -5.8291, -5.8307, -5.5937, -5.7358, -5.941, -5.6421, -5.7587, -5.8978, -5.9021, -5.8442, -5.9238], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.6931, 0.6764, 0.6661, 0.6531, 0.6504, 0.6441, 0.6441, 0.6441, 0.642, 0.637, 0.6324, 0.6324, 0.6324, 0.6324, 0.6309, 0.6227, 0.6165, 0.6165, 0.6165, 0.6165, 0.6165, 0.6165, 0.6165, 0.6165, 0.6165, 0.6165, 0.6156, 0.6143, 0.6136, 0.5971, 0.5923, 0.5637, 0.5525, 0.5104, 0.5847, 0.5367, 0.5789, 0.5097, 0.5281, 0.5768, 0.4274, 0.4735, 0.2944, 0.2043, 0.2961, 0.1815, 0.129, 0.3853, 0.2559, 0.2525, 0.3356, 0.1224, 0.1688, 0.1286, 0.1304, 0.0433, 0.1778, 0.2578, 0.1449, 0.2107, 0.0049, 0.0328, 0.1901, 0.1193, 0.0753, 0.0652, -0.0583, 0.2115, 0.1451, 0.1092, 0.0793, 0.1599, 0.0984, 1.0689, 1.0559, 1.0559, 1.0384, 1.0384, 1.0384, 1.0248, 1.0133, 1.0133, 1.0133, 1.0133, 1.0133, 1.0133, 1.0133, 1.0133, 0.9842, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9744, 0.9701, 0.946, 0.9536, 0.9355, 0.9309, 0.9065, 0.9544, 0.8072, 0.8755, 0.7881, 0.7119, 0.8095, 0.5334, 0.7532, 0.6588, 0.4756, 0.5148, 0.6181, 0.0249, 0.5307, 0.0791, 0.3436, 0.0915, 0.0736, 0.1868, 0.1076, 0.1778, 0.3725, 0.334, 0.2121, -0.1052, 0.0205, -0.0883, -0.1495, 0.2103, 0.305, 0.1046, -0.2248, 0.1641, -0.1482, -0.0222, -0.0956, 0.2185, 0.2691, 0.0758, -0.0476, -0.1416, 0.0834, -0.1991, 0.0692, 1.535, 1.5136, 1.5002, 1.5002, 1.4994, 1.4826, 1.48, 1.4519, 1.4518, 1.4518, 1.4518, 1.4498, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4079, 1.4078, 1.4078, 1.4064, 1.3312, 1.3312, 1.3312, 1.3159, 1.2936, 1.2957, 1.136, 0.942, 1.106, 1.3052, 1.0729, 0.928, 0.9273, 0.5332, 1.1117, 0.5937, 1.0952, 1.1751, 0.9501, 0.9861, 0.1148, 0.0489, 0.9724, 0.3955, -0.1828, 0.1686, -0.0424, 0.7273, 0.0722, -0.2261, -0.0238, -0.4716, -0.4054, 0.1942, 0.1707, -0.2624, -0.139, 0.2278, -0.5941, -0.4663, -0.1914, -0.2903, -0.6668, -0.3091]}, \"token.table\": {\"Topic\": [1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 3, 1, 2, 3, 3, 1, 1, 3, 3, 1, 2, 1, 2, 3, 1, 3, 1, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 1, 2, 3, 2, 2, 1, 1, 3, 2, 2, 3, 1, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 3, 1, 3, 3, 1, 2, 1, 1, 3, 1, 1, 2, 3, 1, 1, 2, 3, 3, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 3, 1, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 1, 2, 2, 1, 2, 3, 1, 2, 1, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 3, 3, 2, 1, 1, 2, 3, 2, 2, 1, 2, 3, 1, 3, 1, 2, 3, 2, 1, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 2, 1, 2, 1, 2, 3, 1, 1, 1, 1, 2, 3, 3, 2, 1, 2, 3, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1], \"Freq\": [0.12256273597528658, 0.857939151827006, 0.8800172076214704, 0.9275146048712796, 0.6284861333103097, 0.13467559999506634, 0.24690526665762166, 0.5685366167881891, 0.3451829459071148, 0.08121951668402702, 0.8549894567886305, 0.10687368209857881, 0.9889498439922277, 0.19753215670101262, 0.19753215670101262, 0.4938303917525316, 0.9275149253292936, 0.5742461784493813, 0.27563816565570304, 0.14930400639683916, 0.30666362495290894, 0.12266544998116359, 0.6133272499058179, 0.6651070245329473, 0.2684616286822174, 0.5906155831008784, 0.16107697720933045, 0.8239039762207596, 0.6651070853985677, 0.8029396717546537, 0.12352918026994672, 0.06176459013497336, 0.6651074518153294, 0.9713618485235689, 0.187194681433597, 0.748778725734388, 0.6650968601748751, 0.17464293340017512, 0.785893200300788, 0.5415895986535598, 0.38684971332397133, 0.07736994266479426, 0.42052172269789895, 0.5046260672374787, 0.9713629070611898, 0.8311870129778886, 0.7393585826746957, 0.6651070907067443, 0.8302250064606326, 0.15095000117466048, 0.03773750029366512, 0.9275152805793117, 0.9275156113151719, 0.0732494637449183, 0.8057441011941013, 0.1464989274898366, 0.5211676378675356, 0.4169341102940285, 0.05211676378675356, 0.5181838064284664, 0.3454558709523109, 0.13434394981478756, 0.9973041705325978, 0.9275135091524429, 0.9973042476835943, 0.44903024789601687, 0.2525795144415095, 0.3087082954285116, 0.9889489302137018, 0.927513511693955, 0.9031405819368424, 0.38387467212393267, 0.6397911202065545, 0.9889487814667741, 0.7812550772545294, 0.1562510154509059, 0.48628828769692345, 0.48628828769692345, 0.5997215465941611, 0.290187845126207, 0.11607513805048279, 0.9713622611721784, 0.27766402491628894, 0.22213121993303114, 0.4997952448493201, 0.6233214208457822, 0.22804442226065202, 0.15202961484043467, 0.8800763622304111, 0.09778626247004568, 0.9713642899662881, 0.8018383895695369, 0.665107037045684, 0.3229369902184245, 0.645873980436849, 0.9713626590079426, 0.44824935431506324, 0.44824935431506324, 0.8716067909688171, 0.5508042952366315, 0.32023505537013464, 0.12168932104065117, 0.9718525539568926, 0.19473849044736158, 0.7140411316403258, 0.12982566029824105, 0.6651070853228374, 0.665107088681669, 0.9482217389523782, 0.5060952035271563, 0.34376277975429487, 0.16233242377286144, 0.7763971348486094, 0.05175980898990729, 0.15527942696972188, 0.5475555148642536, 0.25157956088357597, 0.19238437008744047, 0.5459243150441065, 0.2183697260176426, 0.23656720318577948, 0.5523471708502564, 0.3203613590931487, 0.12151637758705641, 0.6591059198305448, 0.25108796945925516, 0.09415798854722068, 0.4419591460043892, 0.19335712637692026, 0.3590918061285662, 0.9973040969949144, 0.823903506391858, 0.9510278221189721, 0.10566975801321912, 0.11228377931426475, 0.7859864551998533, 0.11228377931426475, 0.3611382557839295, 0.29547675473230595, 0.3447228805210236, 0.9889505662142617, 0.9275144324752844, 0.441092532927478, 0.34307197005470513, 0.21237788622434128, 0.8083117243654627, 0.16166234487309256, 0.04041558621827314, 0.6029055306458446, 0.2368557441822961, 0.1722587230416699, 0.9275146630817295, 0.1299305260043252, 0.2598610520086504, 0.6496526300216259, 0.6651071242724251, 0.28529051266131794, 0.7132262816532948, 0.8825874190577, 0.6769820493944713, 0.2166342558062308, 0.1083171279031154, 0.597009125309272, 0.27205479128017457, 0.13602739564008728, 0.29989792475998245, 0.23991833980798594, 0.4198570946639754, 0.7266701521171028, 0.16515230729934155, 0.09909138437960492, 0.9596801513463252, 0.6649939433134086, 0.3287924704552685, 0.4657893331449637, 0.2191949803035123, 0.9073275914327414, 0.12961822734753448, 0.8936927071004003, 0.8257588568317197, 0.0869219849296547, 0.0869219849296547, 0.8016882685900226, 0.8714556851847983, 0.8018428319965518, 0.414581494621807, 0.08728031465722252, 0.5018618092790295, 0.4139524570215403, 0.5174405712769254, 0.06899207617025672, 0.8800171697738213, 0.5794294710364055, 0.2744665915435605, 0.1524814397464225, 0.9714354105962493, 0.8736877766559609, 0.0970764196284401, 0.927513387274009, 0.9317180580614178, 0.11646475725767723, 0.8018397793424145, 0.20518788766636156, 0.8207515506654463, 0.08361855006639977, 0.8361855006639978, 0.5299792641904876, 0.3886514604063575, 0.08832987736508126, 0.2068916487894015, 0.0689638829298005, 0.7586027122278055, 0.9027812735367727, 0.21455291299209406, 0.5149269911810257, 0.21455291299209406, 0.5110630983508387, 0.2830503313943107, 0.212287748545733, 0.8721308460925425, 0.12459012087036322, 0.8714560101212978, 0.9275148595764019, 0.5548218212836397, 0.38410741473482746, 0.0569048021829374, 0.5283187459871274, 0.38156353876848087, 0.10272864505305254, 0.983128921350007, 0.057831113020588645, 0.9275133615526892, 0.8410091949722793, 0.46094761860986005, 0.3771389606807946, 0.16761731585813094, 0.16248739915169755, 0.22748235881237658, 0.6174521167764507, 0.4922334046455932, 0.2885506165163822, 0.22065635380664522, 0.9596802301265495, 0.1892330856532241, 0.7569323426128964, 0.9442360596974656, 0.9275134833642087, 0.9713622794675442, 0.5668683476797095, 0.26453856225053113, 0.17006050430391284, 0.9275138354147311, 0.8239034306304325, 0.36839048269549646, 0.5417507098463183, 0.08668011357541093, 0.23767565256534143, 0.7130269576960243, 0.5572704096341743, 0.21229348938444734, 0.23883017555750327, 0.9889491641950928, 0.8581903886771849, 0.10727379858464811, 0.9973050627812128, 0.5242233976299838, 0.3145340385779903, 0.17973373633028017, 0.12355876848811997, 0.7413526109287198, 0.12355876848811997, 0.9713646586677205, 0.8825855813200533, 0.32121808721468864, 0.43593883264850597, 0.2523856399543982, 0.9889506516523631, 0.8004363301600715, 0.17306731462920466, 0.45766847741994915, 0.35205267493842246, 0.1877614266338253, 0.9713634757536322, 0.8714583552714426, 0.8723000655243577, 0.7423502846144615, 0.1484700569228923, 0.11877604553831383, 0.6650968569233312, 0.927515527704786, 0.3619004251740473, 0.12063347505801576, 0.48253390023206305, 0.9265815597339394, 0.6651069220763443, 0.9713634382783984, 0.988951837995344, 0.2803662111290694, 0.7476432296775184, 0.6526552375889945, 0.28716830453915754, 0.06526552375889945, 0.5052818254443748, 0.3435916413021749, 0.16169018414219993, 0.2922481360271942, 0.5844962720543884, 0.09741604534239807, 0.6651070258470535, 0.9713650186131243, 0.9901251988944136, 0.32818884441614304, 0.6563776888322861, 0.4128633662609237, 0.4954360395131084, 0.08257267325218473, 0.5859674363998432, 0.2536276963521709, 0.16616987002383612, 0.9889511368784403, 0.8800172156090345, 0.6183072394920262, 0.21724308414584703, 0.16711006472757464, 0.9595787643033645, 0.3517295734487991, 0.4522237372913132, 0.20098832768502808, 0.5450481728812895, 0.3374107736884173, 0.1124702578961391, 0.6651070096001136, 0.35759770025536186, 0.6257959754468833, 0.4304420229259811, 0.4304420229259811, 0.12660059497822973, 0.8245784000765017, 0.6651072851220691, 0.43033901691636395, 0.3825235705923235, 0.16735406213414153, 0.583252122896968, 0.26340418453411457, 0.1505166768766369, 0.5694831053532229, 0.35592694084576426, 0.8018428804616454, 0.551416204840389, 0.34463512802524315, 0.09846717943578376, 0.32098518518194397, 0.1283940740727776, 0.5777733333274991, 0.9715352371287804], \"Term\": [\"absolutely\", \"absolutely\", \"agent\", \"andor\", \"another\", \"another\", \"another\", \"asked\", \"asked\", \"asked\", \"asking\", \"asking\", \"attached\", \"avoid\", \"avoid\", \"avoid\", \"awhile\", \"back\", \"back\", \"back\", \"bag\", \"bag\", \"bag\", \"bagging\", \"bill\", \"bill\", \"bill\", \"blah\", \"blanco\", \"boyfriend\", \"boyfriend\", \"boyfriend\", \"bride\", \"brio\", \"buck\", \"buck\", \"building\", \"burger\", \"burger\", \"came\", \"came\", \"came\", \"cash\", \"cash\", \"certain\", \"certainly\", \"challenge\", \"charcoal\", \"chicken\", \"chicken\", \"chicken\", \"chompie\", \"co\", \"coffee\", \"coffee\", \"coffee\", \"come\", \"come\", \"come\", \"could\", \"could\", \"could\", \"cousin\", \"creme\", \"curry\", \"customer\", \"customer\", \"customer\", \"cuz\", \"de\", \"desk\", \"didnt\", \"didnt\", \"direction\", \"dont\", \"dont\", \"donut\", \"donut\", \"drink\", \"drink\", \"drink\", \"elephant\", \"employee\", \"employee\", \"employee\", \"even\", \"even\", \"even\", \"evening\", \"evening\", \"excited\", \"fell\", \"finger\", \"fish\", \"fish\", \"fitness\", \"flight\", \"flight\", \"flirting\", \"food\", \"food\", \"food\", \"four\", \"fry\", \"fry\", \"fry\", \"fucking\", \"gallo\", \"game\", \"get\", \"get\", \"get\", \"getting\", \"getting\", \"getting\", \"go\", \"go\", \"go\", \"going\", \"going\", \"going\", \"good\", \"good\", \"good\", \"got\", \"got\", \"got\", \"guy\", \"guy\", \"guy\", \"gym\", \"gyro\", \"happy\", \"happy\", \"hungry\", \"hungry\", \"hungry\", \"im\", \"im\", \"im\", \"insurance\", \"irritating\", \"it\", \"it\", \"it\", \"item\", \"item\", \"item\", \"ive\", \"ive\", \"ive\", \"jewish\", \"lady\", \"lady\", \"lady\", \"lax\", \"leave\", \"leave\", \"lee\", \"left\", \"left\", \"left\", \"like\", \"like\", \"like\", \"line\", \"line\", \"line\", \"long\", \"long\", \"long\", \"lost\", \"maam\", \"made\", \"made\", \"made\", \"main\", \"main\", \"mama\", \"manager\", \"manager\", \"manager\", \"mani\", \"massage\", \"matthew\", \"me\", \"me\", \"me\", \"meal\", \"meal\", \"meal\", \"mechanical\", \"minute\", \"minute\", \"minute\", \"mixed\", \"mom\", \"mom\", \"moscato\", \"mousse\", \"mousse\", \"movie\", \"music\", \"music\", \"nail\", \"nail\", \"never\", \"never\", \"never\", \"no\", \"no\", \"no\", \"noodle\", \"oh\", \"oh\", \"oh\", \"one\", \"one\", \"one\", \"onion\", \"onion\", \"online\", \"opinion\", \"order\", \"order\", \"order\", \"ordered\", \"ordered\", \"ordered\", \"pasta\", \"pasta\", \"peach\", \"pedi\", \"people\", \"people\", \"people\", \"pizza\", \"pizza\", \"pizza\", \"place\", \"place\", \"place\", \"plane\", \"plenty\", \"plenty\", \"polish\", \"pot\", \"promised\", \"really\", \"really\", \"really\", \"reseated\", \"reservation\", \"restaurant\", \"restaurant\", \"restaurant\", \"rib\", \"rib\", \"right\", \"right\", \"right\", \"ring\", \"roll\", \"roll\", \"root\", \"said\", \"said\", \"said\", \"salsa\", \"salsa\", \"salsa\", \"sampler\", \"sapporo\", \"say\", \"say\", \"say\", \"self\", \"server\", \"server\", \"service\", \"service\", \"service\", \"shed\", \"simple\", \"simply\", \"since\", \"since\", \"since\", \"skill\", \"skirt\", \"slice\", \"slice\", \"slice\", \"slider\", \"sorbet\", \"space\", \"stale\", \"sweet\", \"sweet\", \"table\", \"table\", \"table\", \"take\", \"take\", \"take\", \"tasted\", \"tasted\", \"tasted\", \"taxi\", \"tempura\", \"thai\", \"thanks\", \"thanks\", \"thing\", \"thing\", \"thing\", \"time\", \"time\", \"time\", \"toast\", \"tokyo\", \"told\", \"told\", \"told\", \"topping\", \"two\", \"two\", \"two\", \"u\", \"u\", \"u\", \"very\", \"waiter\", \"waiter\", \"wanted\", \"wanted\", \"wanted\", \"wasted\", \"wedding\", \"well\", \"well\", \"well\", \"went\", \"went\", \"went\", \"were\", \"were\", \"wm\", \"would\", \"would\", \"would\", \"you\", \"you\", \"you\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 1, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el2960020730177611205131982802\", ldavis_el2960020730177611205131982802_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el2960020730177611205131982802\", ldavis_el2960020730177611205131982802_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el2960020730177611205131982802\", ldavis_el2960020730177611205131982802_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "1     -0.037344  0.054880       1        1  48.584104\n",
       "0     -0.039820 -0.053718       2        1  31.504864\n",
       "2      0.077164 -0.001162       3        1  19.911032, topic_info=        Term       Freq       Total Category  logprob  loglift\n",
       "611       me  45.000000   45.000000  Default  30.0000  30.0000\n",
       "212    pizza  30.000000   30.000000  Default  29.0000  29.0000\n",
       "2180    nail  11.000000   11.000000  Default  28.0000  28.0000\n",
       "505       im  60.000000   60.000000  Default  27.0000  27.0000\n",
       "808       no  14.000000   14.000000  Default  26.0000  26.0000\n",
       "...      ...        ...         ...      ...      ...      ...\n",
       "291     good  11.307334   90.522777   Topic3  -5.7587  -0.4663\n",
       "109     told   9.838901   59.840800   Topic3  -5.8978  -0.1914\n",
       "36      even   9.796684   65.776658   Topic3  -5.9021  -0.2903\n",
       "123    would  10.380770  101.556682   Topic3  -5.8442  -0.6668\n",
       "69    minute   9.585908   65.581752   Topic3  -5.9238  -0.3091\n",
       "\n",
       "[254 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "1127      1  0.122563  absolutely\n",
       "1127      2  0.857939  absolutely\n",
       "2231      3  0.880017       agent\n",
       "1491      2  0.927515       andor\n",
       "160       1  0.628486     another\n",
       "...     ...       ...         ...\n",
       "123       3  0.098467       would\n",
       "2009      1  0.320985         you\n",
       "2009      2  0.128394         you\n",
       "2009      3  0.577773         you\n",
       "1109      1  0.971535       young\n",
       "\n",
       "[355 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[2, 1, 3])"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pyLDAvis.gensim_models.prepare(lda, c, d)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
